{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6536495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "# Most important library for fine tuning\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from pprint import pprint\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928dc8a",
   "metadata": {},
   "source": [
    "## Import and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49542f2",
   "metadata": {},
   "source": [
    "#### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9277289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b00ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fcfe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data = pd.DataFrame(data['unsupervised'])\n",
    "train_data = pd.DataFrame(data['train'])\n",
    "test_data = pd.DataFrame(data['test'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de359b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42f7579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     24904\n",
       "label        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c48115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    25000 non-null  object\n",
      " 1   label   25000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4522cb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6bed3",
   "metadata": {},
   "source": [
    "### Lets have a look into the random row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ab3075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Arguably this is a very good \"sequel\", better than the first live action '\n",
      " 'film 101 Dalmatians. It has good dogs, good actors, good jokes and all right '\n",
      " 'slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, '\n",
      " 'is now a lover of dogs and very kind to them. Many, including Chloe Simon, '\n",
      " 'owner of one of the dogs that Cruella once tried to kill, do not believe '\n",
      " 'this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe '\n",
      " 'that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have '\n",
      " 'given birth to three cute dalmatian puppies! Little Dipper, Domino and '\n",
      " 'Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious '\n",
      " 'macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt '\n",
      " '(another baddie, the name should give a clue), this is a good family film '\n",
      " 'with excitement and lots more!! One downfall of this film is that is has a '\n",
      " 'lot of painful slapstick, but not quite as excessive as the last film. This '\n",
      " 'is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)')\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(train_data)-1)\n",
    "pprint(train_data.iloc[random_index,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adca53",
   "metadata": {},
   "source": [
    "## Step:1 Importing the tokenizer from the hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dd33bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de58d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_reviews = train_data['text'].apply(lambda x: tokenizer(x, add_special_tokens= True))\n",
    "review_token_length = tokenized_reviews.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf180dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shorest token length: 2\n",
      "Max token length: 2\n",
      "Mean token length: 2.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shorest token length: {review_token_length.min()}\")\n",
    "print(f\"Max token length: {review_token_length.max()}\")\n",
    "print(f\"Mean token length: {review_token_length.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52757f1",
   "metadata": {},
   "source": [
    "# Note: Method to convert the pandas dataset to the hugging face dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff8dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "hugging_face_fromat = Dataset.from_pandas(train_data)\n",
    "print(hugging_face_fromat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae98621",
   "metadata": {},
   "source": [
    "## Step:2 Next we need to tokenize the data.\n",
    "\n",
    "##### padding=\"longest\": This setting ensures that all sequences in a batch are padded to match the length of the longest sequence within that batch.\n",
    "\n",
    "#### truncation=True: This parameter ensures that any sequence exceeding the model's maximum allowable length is truncated to fit within that limit. Truncation prevents errors that can occur when input sequences are too long for the model to handle.\n",
    "\n",
    "#### batched= True: This parameter ensures that we tokenize the text in batches.\n",
    "\n",
    "#### batch_size= 10: This parameter ensures that our batch size of 10 rows at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a0e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf51ce917254d77835d0d437964a541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding='longest', truncation=True)\n",
    "\n",
    "tokenized_dataset = hugging_face_fromat.map(tokenize_function, batched=True, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3e7562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300964f2",
   "metadata": {},
   "source": [
    "## Step 3: Calling the pretrained model from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee82a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('prajjwal1/bert-tiny', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544966b9",
   "metadata": {},
   "source": [
    "### Step 4: Passing the test dataset to check the accuracy before fine-tuning the model.\n",
    "\n",
    "#### do_train = False: This parameter ensures that model is not in the training or fine-tuning mode.\n",
    "\n",
    "#### do_eval = True: This parameter ensures that model is in evaluation mode. We can evaluate the model with our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d867a0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd0f262fd144043b572f6113bfee101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_hugg_format = Dataset.from_pandas(test_data)\n",
    "tokenized_test_dataset = test_hugg_format.map(tokenize_function, batched= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d5e3bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6908232569694519, 'eval_model_preparation_time': 0.0022, 'eval_runtime': 345.3207, 'eval_samples_per_second': 72.396, 'eval_steps_per_second': 9.05}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./temp_results\",  # Directory to save model checkpoints, logs, and other outputs\n",
    "\n",
    "    # Training, Evaluation, and Prediction Flags\n",
    "    do_train = False,  # Whether to perform training\n",
    "    do_eval = True,  # Whether to perform evaluation on the validation set\n",
    "    do_predict= False, # Indicates whether to perform predictions on the test set. If True, you can call the predict() method with your test dataset. 'predictions_output = trainer.predict(tokenized_test_dataset)'\n",
    "\n",
    "    # Optimization Parameters\n",
    "    learning_rate=5e-5, # The initial learning rate for the optimizer. Affects how quickly the model adapts to the problem.\n",
    "\n",
    "    #Training Control Parameters\n",
    "    num_train_epochs=3, # Total number of training epochs to perform. An epoch is one full pass through the training dataset.\n",
    "    max_steps= 2, # If set to a positive number, training will stop after this many steps, overriding num_train_epochs.\n",
    "    #per_device_train_batch_size=16, # Batch size per device (GPU/TPU/CPU) during training. Larger batch sizes can lead to faster training but require more memory.\n",
    "    #per_device_eval_batch_size= 500, # Batch size per device (GPU/TPU/CPU) during evaluation. Larger batch sizes can lead to faster training but require more memory.\n",
    "   \n",
    "    # Logging \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "\n",
    "    # Evalution \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps= 100,\n",
    "    \n",
    "    seed = 40\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    eval_dataset = tokenized_test_dataset\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76b96f",
   "metadata": {},
   "source": [
    "# Some training configuration\n",
    "\n",
    "# üóÇÔ∏è Output Configuration\n",
    "\n",
    "- **`output_dir`** (`str`):  \n",
    "  Specifies the directory where model checkpoints, logs, and other outputs will be saved.\n",
    "\n",
    "- **`overwrite_output_dir`** (`bool`):  \n",
    "  If set to `True`, the contents of the `output_dir` will be overwritten if it already exists.\n",
    "\n",
    "---\n",
    "\n",
    "# üß™ Training, Evaluation, and Prediction Flags\n",
    "\n",
    "- **`do_train`** (`bool`):  \n",
    "  Indicates whether to perform training. If `True`, the `train()` method will execute the training loop.\n",
    "\n",
    "- **`do_eval`** (`bool`):  \n",
    "  Indicates whether to perform evaluation on the validation set. If `True`, evaluation is conducted during training at specified intervals.\n",
    "\n",
    "- **`do_predict`** (`bool`):  \n",
    "  Indicates whether to perform predictions on the test set. If `True`, you can call the `predict()` method with your test dataset.\n",
    "\n",
    "---\n",
    "\n",
    "# üßÆ Optimization Parameters\n",
    "\n",
    "- **`learning_rate`** (`float`):  \n",
    "  The initial learning rate for the optimizer. Affects how quickly the model adapts to the problem.\n",
    "\n",
    "- **`weight_decay`** (`float`):  \n",
    "  Weight decay (L2 penalty) to apply to the optimizer. Helps prevent overfitting by penalizing large weights.\n",
    "\n",
    "- **`adam_beta1`** (`float`):  \n",
    "  The beta1 parameter for the Adam optimizer, controlling the exponential decay rate for the first moment estimates.\n",
    "\n",
    "- **`adam_beta2`** (`float`):  \n",
    "  The beta2 parameter for the Adam optimizer, controlling the exponential decay rate for the second moment estimates.\n",
    "\n",
    "- **`adam_epsilon`** (`float`):  \n",
    "  A small constant for numerical stability in the Adam optimizer.\n",
    "\n",
    "- **`max_grad_norm`** (`float`):  \n",
    "  Maximum gradient norm for gradient clipping. Prevents exploding gradients by capping their norm.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Training Control Parameters\n",
    "\n",
    "- **`num_train_epochs`** (`float`):  \n",
    "  Total number of training epochs to perform. An epoch is one full pass through the training dataset.\n",
    "\n",
    "- **`max_steps`** (`int`):  \n",
    "  If set to a positive number, training will stop after this many steps, overriding `num_train_epochs`.\n",
    "\n",
    "- **`per_device_train_batch_size`** (`int`):  \n",
    "  Batch size per device (GPU/TPU/CPU) during training. Larger batch sizes can lead to faster training but require more memory.\n",
    "\n",
    "- **`per_device_eval_batch_size`** (`int`):  \n",
    "  Batch size per device during evaluation.\n",
    "\n",
    "- **`gradient_accumulation_steps`** (`int`):  \n",
    "  Number of update steps to accumulate before performing a backward/update pass. Useful for training with large batch sizes that don't fit in memory.\n",
    "\n",
    "---\n",
    "\n",
    "# üìà Evaluation and Logging\n",
    "\n",
    "- **`eval_strategy`** (`str`):  \n",
    "  Determines when to evaluate the model during training. Options:\n",
    "  - `\"no\"`: No evaluation during training.\n",
    "  - `\"steps\"`: Evaluate every `eval_steps`.\n",
    "  - `\"epoch\"`: Evaluate at the end of each epoch.\n",
    "\n",
    "- **`eval_steps`** (`int`):  \n",
    "  Number of update steps between two evaluations if `evaluation_strategy` is set to `\"steps\"`.\n",
    "\n",
    "- **`logging_dir`** (`str`):  \n",
    "  Directory for storing logs.\n",
    "\n",
    "- **`logging_strategy`** (`str`):  \n",
    "  Determines when to log training metrics. Options:\n",
    "  - `\"no\"`: No logging.\n",
    "  - `\"steps\"`: Log every `logging_steps`.\n",
    "  - `\"epoch\"`: Log at the end of each epoch.\n",
    "\n",
    "- **`logging_steps`** (`int`):  \n",
    "  Number of update steps between two logs if `logging_strategy` is set to `\"steps\"`.\n",
    "\n",
    "- **`save_strategy`** (`str`):  \n",
    "  Determines when to save model checkpoints. Options:\n",
    "  - `\"no\"`: No saving.\n",
    "  - `\"steps\"`: Save every `save_steps`.\n",
    "  - `\"epoch\"`: Save at the end of each epoch.\n",
    "\n",
    "- **`save_steps`** (`int`):  \n",
    "  Number of update steps between two checkpoint saves if `save_strategy` is set to `\"steps\"`.\n",
    "\n",
    "- **`save_total_limit`** (`int`):  \n",
    "  Limits the total number of checkpoints. Older checkpoints are deleted when the limit is reached.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öôÔ∏è Advanced Features\n",
    "\n",
    "- **`fp16`** (`bool`):  \n",
    "  Whether to use 16-bit (mixed) precision training. Can lead to faster training and reduced memory usage on compatible hardware.\n",
    "\n",
    "- **`fp16_opt_level`** (`str`):  \n",
    "  Optimization level for mixed precision training. Options: `\"O0\"`, `\"O1\"`, `\"O2\"`, `\"O3\"`.\n",
    "\n",
    "- **`load_best_model_at_end`** (`bool`):  \n",
    "  Whether to load the best model found during training at the end of training, based on the evaluation metric specified by `metric_for_best_model`.\n",
    "\n",
    "- **`metric_for_best_model`** (`str`):  \n",
    "  The metric to use to compare two different models.\n",
    "\n",
    "- **`greater_is_better`** (`bool`):  \n",
    "  Whether the `metric_for_best_model` should be maximized or minimized.\n",
    "\n",
    "- **`report_to`** (`List[str]`):  \n",
    "  The list of integrations to report the results and logs to. Supported platforms include `\"tensorboard\"`, `\"wandb\"`, `\"comet_ml\"`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "# üîß Miscellaneous\n",
    "\n",
    "- **`seed`** (`int`):  \n",
    "  Random seed for reproducibility. Ensures that training results are consistent across runs.\n",
    "\n",
    "- **`data_seed`** (`int`):  \n",
    "  Random seed to be used with data samplers. If not set, it will use the value of `seed`.\n",
    "\n",
    "- **`gradient_checkpointing`** (`bool`):  \n",
    "  If `True`, use gradient checkpointing to save memory at the expense of a slower backward pass.\n",
    "\n",
    "- **`label_smoothing_factor`** (`float`):  \n",
    "  The label smoothing factor to use. Zero means no label smoothing.\n",
    "\n",
    "- **`optim`** (`str`):  \n",
    "  The optimizer to use. Options include `\"adamw_torch\"`, `\"adamw_hf\"`, `\"adamw_torch_fused\"`, etc.\n",
    "\n",
    "- **`lr_scheduler_type`** (`str`):  \n",
    "  The learning rate scheduler to use. Options include `\"linear\"`, `\"cosine\"`, `\"polynomial\"`, etc.\n",
    "\n",
    "- **`warmup_steps`** (`int`):  \n",
    "  Number of steps used for a linear warmup from 0 to `learning_rate`.\n",
    "\n",
    "- **`warmup_ratio`** (`float`):  \n",
    "  The ratio of total training steps used for a linear warmup from 0 to `learning_rate`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e2369",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
